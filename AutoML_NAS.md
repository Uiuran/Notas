# AutoML, Google's approach to Neural Architecture Search (NAS)

From Google Blog:

*" At Google, we have successfully applied deep learning models to many applications, from image recognition to speech recognition to machine translation. Typically, our machine learning models are painstakingly designed by a team of engineers and scientists. This process of manually designing machine learning models is difficult because the search space of all possible models can be combinatorially large â€” a typical 10-layer network can have ~1010 candidate networks! For this reason, the process of designing networks often takes a significant amount of time and experimentation by those with significant machine learning expertise. "*

Each google Machine Learning article/service/product rarely requires less than 5 to more very experienced data/ai engineers to find the (possible) optimal ML/DL Pipeline/Architecture.

Everybody has a dream to model customily the data, possible the most bizarre data, from scratch and without (or with too few) an ideia of what parametrizations and architectures to use, the use of optimization algorithms and meta-heuristic optimizators came into hand to help understand how we can automatize the designing of AI systems.

Particulary, understanding data properties, possible features in relation to architectures and pipelines are a wide and open field of research named NAS and also comprises Google's AutoML approach to designing.

